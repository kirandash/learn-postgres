# Mastering PostgreSQL: Build Lightning-Fast, optimized, Scalable Databases

-- DAY 1 --

## 1. Introduction to PostgreSQL

### 1.1 Introduction

### 1.2 Setup

- Install postgres - we are using v17
  - https://www.postgresql.org/download/
    - Homebrew: https://formulae.brew.sh/formula/postgresql@17 or
    - postgress.app: https://postgresapp.com/
- PostgreSQL GUIs
  - https://tableplus.com/download
- psql cli: https://www.postgresql.org/docs/current/app-psql.html#:~:text=psql%20is%20a%20terminal%2Dbased,or%20from%20command%20line%20arguments.
  - terminal-based front-end to PostgreSQL
- DB version Management Tool
  - https://dbngin.com/

### 1.3 Postgres and Other Databases out there

- Other DBs
  - MySQL, SQLite
- Benefits of using Postgres
  - Extensibility
  - Performance
  - Powerful and feature rich
  - Community support
  - It is right tool for a lot of scenarios but not all
- We wil focus on Postgres ex: full text search
  - but in other scenarios such as real-time data, we might use other databases or elastic search etc.
- We will cover in depth some use cases where Postgres shines but also where it doesn't

### 1.4 psql cli

- we are going to use tableplus mainly but feel free to use psql cli
- make sure you have psql installed
  - `psql --version`
- connect to a database
  - `psql -d master_postgres_demo`
  - `psql -U kirandash -d master_postgres_demo`
- list databases
  - `\l`: this is the meta command
  - alternatively, you can run SQL command: `SELECT datname FROM pg_database;`
- create a database (not psql command, but SQL)
  - `CREATE DATABASE master_postgres_demo;`
- list tables
  - `\dt`
- help
  - `\?`
- quit
  - `\q`
- list users
  - `\du`
- describe 🔥
  - \d
  - describe table
    - `\d kirantest_example1`
- Expanded display 🔥
  - `\x auto`
  - to turn off: `\x`
- Note: psqlrc file
  - `~/.psqlrc`
  - `psqlrc` is a configuration file that allows you to set defaults for your psql session
  - https://wiki.postgresql.org/wiki/Psqlrc

### 1.5 What is a PostgreSQL schema?

- In other databases ex: MySQL or SQLite you have a database and tables

  - In Postgres, you have a database and schemas
  - A schema is a namespace that contains named database objects such as tables, views, indexes, data types, functions, and operators
  - Each database contains a `public` schema by default and can contain multiple schemas
  - each schema can contain multiple tables

    <img src="./assets/schema.png" alt="Schema Illustration" height="300" />

- Comparison with SQLite:
  - You have a file and database
    - and each database has multiple tables
- Comparison with MySQL:
  - You have a MySQL server
    - and each server can have multiple databases
      - and each database can have multiple tables
- Postgres is a bit different
  - You have a Postgres server or Postgres cluster or Postgres process
    - and each server can have multiple databases
      - and each database can have multiple schemas
        - and each schema can have multiple tables

### 1.6 What is a Table Schema and Guidelines on defining it?

- Note that the PostgreSQL schema is different from the table schema
  - Table schema is the structure of the table
  - Schema in Postgres is a namespace that contains named database objects. So please understand the difference based on the context
- Table Schema Guidelines 🔥:
  - Make sure the schema is SMALL and not too big
  - Make sure the schema is SIMPLE
  - Make sure the schema is REPRESENTATIVE OF THE DATA to be stored 🔥 (Very Important)
    - Postgres has a wide range of data types. As a developer you need to choose the right data type for the right data
    - Why it is important?
      - this is not just to save the data space because space is cheap
      - but it is Mainly to make sure the bounds and indexes etc are correctly applied and postgres has a lot of utilities that might be helpful based on the data type
        - ex: postgres has uuid data type, jsonb data type, etc. so use them rather than using text or varchar
      - it will help with DX and also with indexing and performance etc.

### 1.8 TablePlus

- TablePlus is a modern, native tool with an elegant UI that allows you to simultaneously manage multiple databases such as MySQL, PostgreSQL, SQLite, Microsoft SQL Server, Redis, and more.
- I am going to use TablePlus in this course
- I will be using the free version of TablePlus

## 2. Fundamental Data Types:

### 2.1 Integer Data Types

- Smallint or Int2

  - Storage: It uses 2 bytes of storage.
  - Range: -32768 to +32767 (-2^15 to 2^15 - 1)
  - Use case: It is used when you need to store small integers. Ex: Age does not need INTEGER OR BIGINT
  - In MySQL there is a concept of `UNSIGNED` or `SIGNED`. In Postgres, there is no such concept. So, you can store both positive and negative numbers or you can add a **check constraint** to make sure it is positive
  - It sets the COMPACT data type for the data but it does not set the bounds. So, you can store any number in it. If you want to set the bounds, you can use `CHECK` constraint

- Integer or Int4

  - Storage: It uses 4 bytes of storage.
  - Range: -2147483648 to +2147483647 (-2^31 to 2^31 - 1)
  - Use case: It is used when you need to store integers. Ex: zipCode

- Bigint or Int8

  - Storage: It uses 8 bytes of storage.
  - Range: -9223372036854775808 to +9223372036854775807 (-2^63 to 2^63 - 1)
  - Use case: It is used when you need to store large integers. Ex: phone number

### 2.2 Fractional Data Types - Numeric

- Integers are fast and efficient, but they are not suitable for storing fractional numbers because they are not precise
  - ex: weather temperature today is 25.5 but we don't want to store the decimal then we can use integer
- Floating point numbers are approximate and not precise
  - Floating points are faster than numeric but they are not precise
  - ex: currency prices, we need to be close but not exact
- Numeric data types:

  - used to store numbers with a fractional component
  - Numeric data types are precise and accurate but they are slower and use more storage than the integer data types and floating point data types
  - ex: research data, scientific data, financial data, etc.

- Numeric
  - https://neon.tech/postgresql/postgresql-tutorial/postgresql-numeric
  - The NUMERIC (or DECIMAL) data type in PostgreSQL is highly flexible and can represent a virtually unlimited range of values, constrained only by the maximum precision and scale allowed by PostgreSQL.
  - Range: -10^131072 to 10^131072
  - Storage: variable
  - argument: precision and scale
    - precision: total number of digits
    - scale: number of digits to the right of the decimal point
    - ex: `NUMERIC(5, 2)` means 5 digits in total and 2 digits to the right of the decimal point
      - ex: 123.45 or 12.34 will work but 1234.56 will not work because the total number of digits is 6 which is more than 5. another ex: 123.456 will not work because the number of digits to the right of the decimal point is 3 which is more than 2
    - scale is optional
      - ex: `NUMERIC(5)` means 5 digits in total and 0 digits to the right of the decimal point
    - scale can be negative
      - ex: `NUMERIC(5, -2)` means 5 digits in total and 2 digits to the left of the decimal point

-- DAY 2 --

### 2.3 Fractional Data Types - Floating Point (real, double precision)

- https://www.postgresql.org/docs/current/datatype-numeric.html
- supports fraction, not precise (approx) but fast
- use case:
  - weather, temperature, etc.
- Real:
  - Storage: 4 bytes (32 bits)
  - Precision: 6 decimal digits precision
  - ex: 123.456
  - alias: float4
  - Note: `FLOAT(p) Syntax` where if p is 1-24, then it is internally mapped to real i.e. 6 decimal digits precision
- double precision:
  - Storage: 8 bytes (64 bits)
  - Precision: 15 decimal digits precision
  - ex: 123.456789012345
  - alias: float8
  - Note: `FLOAT(p) Syntax` where if p is 25-53, then it is internally mapped to double precision i.e.e 15 decimal digits precision

### 2.4 Compare speed of different data types 🔥

### 2.5 Monetary Data Type - Money 🤑 (Not recommended)

- https://www.postgresql.org/docs/current/datatype-money.html
- DO NOT USE MONEY DATA TYPE 🚨
  - It is not precise as it is only precise to 2 decimal places
  - It is not recommended to use the money data type as it defaults to USD
- lc_monetary
  - The lc_monetary configuration parameter determines the currency symbol to be used by the to_char function when converting a money value to a string.
  - ex: `SET lc_monetary TO 'en_US.UTF-8';`
  - This only sets the currency symbol but does not automatically convert the number to the currency

### 2.6 Solutions to store money? (Recommended)

- store as integer (used by stripe and other similar companies)

  - fastest and most efficient but slightly less accurate
  - store as cents
  - ex: 100 cents = 1 dollar
  - ex: 10000 cents = 100 dollars

- store as numeric

  - precise and accurate
  - store as dollars
  - ex: 100.00 dollars

- store currency identifier in a new column along with the amount
  - ex: currency: USD, amount: 100.00

### 2.7 Infinity and NaN values for different data types (Rarely used)

- Theory:

  - numeric data type allows 'NaN' and 'Infinity' value but 'Infinity' will not be allowed if we set numeric bound ex: numeric(5,4)
  - integer does not allow 'NaN' or 'Infinity' value
  - real data type allows 'NaN' and 'Infinity' value
  - double precision data type allows 'NaN' and 'Infinity' value
  - Note: 'Inf' is also allowed as 'Infinity'
  - '-inf' is also allowed as '-Infinity'

- Use case for 'NaN' to be stored in the database:

  - ex: scientific data, research data, etc.
  - rarely used by me

- Use case for 'Infinity' to be stored in the database:
  - ex: in scenarios where you need to store a value that is greater than the maximum value that can be stored in the data type
  - ex if we are using real data type and if the value is greater than 3.4e38 then we can store it as 'Infinity'

### 2.8 Casting types in PostgreSQL using cast fn or cast operator(::), `pg_typeof`, `pg_column_size`

- https://neon.tech/postgresql/postgresql-tutorial/postgresql-cast
- cast is a function that converts a value of one data type to another
- use `cast` fn if you want portability or want to change to another database in the future
  - ex: `SELECT cast(98765 as money);`
- use `::` operator if you want to use the native syntax of Postgres
  - ex: `SELECT 98765::money;`
- `pg_typeof` is a function that returns the data type of the argument
- My recommendation is to use `::` operator as it is more readable and concise
- But if you are a developer who develops for multiple databases then you might want to use `cast` fn
- `pg_column_size` is a function that returns the size of the argument in bytes

### 2.9 Character Data Types - CHAR, VARCHAR, TEXT

- Three types of character data types in Postgres:
  - CHAR: Fixed length, padded with spaces
    - ex: `CHAR(5)`: 'abc '
    - DO NOT USE CHAR DATA TYPE 🚨
      - Drawbacks:
        - It is fixed length which means it will not allow you to store more than the specified length
        - it is padded with spaces. The padding is something that you might not want.
          - And it impacts a little bit on the storage because of the additional padded spaces.
          - And it also impacts a little bit on the performance because now developers will have to trim the spaces before using the data
          - Comparison of same text with different lengths might return false because of the padding
        - It is not efficient as it uses the same storage as VARCHAR and CHAR is not better than VARCHAR
      - How to store fixed length data?
        - Use VARCHAR and add a check constraint to make sure the length is fixed
  - VARCHAR (character varying): Variable length, no padding
    - ex: `VARCHAR(5)`: 'abc' or `VARCHAR`: 'abc'
    - VARCHAR without bounds is equivalent to TEXT
  - TEXT: Variable length, no padding
    - ex: `TEXT`: 'abc'
- Note that the underlying data structure is the same for all three data types

- If we save a large string in TEXT or VARCHAR without any constraint, postgres will use TOAST (The Oversized-Attribute Storage Technique) to store the large string
  - TOAST is a mechanism that allows PostgreSQL to store large values in a separate area of the disk and only store a reference to the large value in the table
  - TOAST is transparent to the user and is used to store large values in a more efficient way
- My Recommendation:
  - Don't use CHAR data type
  - Use VARCHAR without bounds or TEXT. I mostly use TEXT because it is more readable and concise
  - If you are using VARCHAR with bounds, make sure the bounds are representative of the data to be stored ex: for title of a blog post you can use VARCHAR(255) but for a blog post content you can use TEXT. or for username you can use VARCHAR(50) etc.

### 2.10 Check Constraint 🔥

- This is a constraint that allows you to specify a condition that must be met before data can be inserted or updated in a table
  - ex: `CHECK (age > 0)` or `CHECK (age BETWEEN 0 AND 100)` for age column which might be a SMALLINT data type which has a range of -32768 to +32767
  - ex: `CHECK (length(title) <= 255)` for title column which might be a VARCHAR(255) data type
- use `CONSTRAINT` keyword to define a check constraint
  - ex: `CONSTRAINT age_must_be_positive CHECK (age > 0)`
  - This will be helpful for other developers to understand the constraint and is good for logging and debugging
- Note that the check constraint can be applied to a column or a table
  - ex: `ALTER TABLE kirantest_example1 ADD CONSTRAINT age_must_be_positive CHECK (age > 0);`
- Use table constraint if you want to apply the constraint to multiple columns (Good Practice but not mandatory. You can also apply the constraint to multiple columns using column constraint but it is not a good practice)
  - ex: `CONSTRAINT fathers_age_must_be_gt_children_age CHECK (fathersAge > age)`
- Check Constraints are very powerful and can be used to enforce business rules, data integrity, etc.
  - Note that some developer might not like to put business logic in the database but it is a good practice to put some business logic in the database to enforce data integrity.
- My Recommendation:
  - Use check constraints to enforce data integrity and business rules
  - Make sure the check constraint is representative of the data to be stored
    - Ex: check constraint that define the data type bounds are good business rules to enforce
    - Ex: business logic such as trigger that sends an email when a user is created is not a good business rule to enforce using check constraint in the database layer. And you should put this logic in the application layer
  - Make sure the check constraint is simple and easy to understand

-- DAY 3 --

### 2.11 Domain Types 🔥

- https://www.postgresql.org/docs/current/domains.html
- A domain is a user-defined data type that is based on another underlying type. Optionally, it can have constraints that restrict its valid values to a subset of what the underlying type would allow. Otherwise it behaves like the underlying type — for example, any operator or function that can be applied to the underlying type will work on the domain type. The underlying type can be any built-in or user-defined base type, enum type, array type, composite type, range type, or another domain.
- Domain types can only be applied at column level and not at table level
  - while check constraints can be applied at column level or table level
- Note that domain types and check constraints can be modified. When you do, it will only be applied to the new data that is inserted or updated. The existing data will not be validated against the new domain type or check constraint
- Recommendation:
  - Use domain type over check constraint for column level constraints
    - because domain type is more readable and concise and reusable
  - Use check constraint for table level constraints

### 2.12 Charset/Encoding and collation

- `\l` to list databases and their encoding and Collate
  <img
    src="./assets/encoding_collate.png"
    alt="Encoding Collate Illustration"
    height="300"
  />
- Encoding: The character set encoding used in the database
  - ex: UTF8, LATIN1, etc.
  - UTF8 is the most common encoding used as it supports a wide range of characters, emojis etc and is the default encoding in Postgres
  - If data is not legal and not valid in the encoding then it will be stored as `?`
- Collation: Collation defines a set of rules for comparing characters in a character set
  - ex: en_US.UTF-8, en_IN.UTF-8, C etc.
  - en_US.UTF-8 is the most common collation used as it is the default collation in Postgres
  - Collation is used to sort and compare strings
  - If you want to sort strings in a different language, you can use a different collation
- Note that some of us might have C collation by default which is language-independent and is faster than other collations
- Recommendation:
  - Use UTF8 encoding and en_US.UTF-8 collation as it is the most common and widely used encoding and collation
  - If you are building a multi-language application, you might want to use a different encoding and collation
- There is also a client encoding which is the character set encoding used by the client application. If the client encoding is different from the database encoding, then client will convert the data to the client encoding before sending it to the database and vice versa

  - to show the client encoding: `SHOW client_encoding;`
  - ex: `SET client_encoding TO 'UTF8';`
  - Recommendation: do not change the client encoding unless you have a good reason to do so because some data might be lost if the client encoding is changed

- Ex of collation: `SELECT 'sourav' = 'SOURAV' COLLATE "en_US.UTF-8" AS result;`
- We can create a custom collation that is case-insensitive. But note that we have better ways to do this without using Custom collation
- Recommendation:
  - Ideally I won't use custom collation because it is not needed in most cases 🚨
  - ex: for case insensitive search,
    - you can do it on client side
    - or you can use `ILIKE` operator in Postgres. This is good but not index assisted
    - you can create another column that stores the lowercase of the column and then you can search on that column.
    - in future we will see generated columns and functional indexes which will help in this scenario ✅
- Note that you also set custom collation for a specific column or a specific index

### 2.13 Binary Data types - BYTEA

- Varying size column
- can store up to 1 GB of data
- when data is large postgres will use TOAST to store the data
- Recommendation:

  - Use BYTEA data type to store binary data. Or to save text data as binary data
  - If you need to store files use a file storage system like S3, or other S3 compatible service like R2, GCS, etc. and then use a CDN. Some managed databases like RDS, Xata etc store BYTEA data till 5 GB and then automatically move the data to S3. DO NOT USE BYTEA data type to store files in the database 🚨
    - https://xata.io/
    - https://aws.amazon.com/rds/
    - If you do it on your own then if the file is deleted from the file storage system then the data in the database will be useless and we will have to handle the cleanup of the data in the database or the sync. But if you use a managed database then the managed database will take care of the cleanup and sync
  - If file size is small then you can store it in the database but make sure you have a good reason to do so (Not recommended)

- `SHOW bytea_output;` to show the bytea output - hex or escape, hex is the default. RECOMMENDED
- `SET bytea_output TO 'escape';` to set the bytea output to escape - this is useful when you want to see the binary data in a more readable format but NOT RECOMMENDED as this might loose some data

### 2.14 md5 hash function, sha256 hash function

- md5: `SELECT md5('hello');` to get the md5 hash of the string
  - DO NOT USE MD5 TO STORE SECURE DATA 🚨
  - Super fast but not secure
  - Use it when you want to compress large data and compare it with another data to do strict equality check. Use it with uuid so that the column size is the smallest ex: `SELECT md5('Kiran Kumar Dash')::uuid;`
  - Using md5 might cause security audit failure
  - use sha256 or bcrypt for secure data

### 2.15 UUID data type

- A UUID is written as a sequence of lower-case hexadecimal digits, in several groups separated by hyphens, specifically a group of 8 digits followed by three groups of 4 digits followed by a group of 12 digits, for a total of 32 digits representing the 128 bits. An example of a UUID in this standard form is: `a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11`
- https://www.postgresql.org/docs/current/datatype-uuid.html
- UUID as data type
- UUID as primary key (to cover later)
- UUID is much more compact and is faster to operate
  - store uuids as UUID (16 bytes) than as text (40 bytes approx)
- postgres can generate uuid `gen_random_uuid()`
  - 🚨 This is not good for using as a primary key because it is not sequential and it is not good for indexing
  - There are other ways to generate uuids that are sequential and are good for indexing
    - uuidv1 till uuidv7
    - For uuidv7: the first 8 bytes are the timestamp and the last 8 bytes are the random bytes
      - ✅ Recommended: uuidv7 is not yet implemented in Postgres by default. But you can add extension to use it. Also you might find it on managed databases like RDS, Xata etc.
- Recommended:
  - Use UUID data type to store UUIDs because it's more compact and faster to operate
  - Do not use TEXT data type to store UUIDs

### 2.16 Boolean Data Type

- True or False
- Storage: 1 byte - super compact
- Other databases actually don't have a boolean data type but they have a boolean which is an Integer data type beneath the hood
- But for Postgres, it is a separate data type
- Recommended:
  - If you want to save true or false then use BOOLEAN data type
  - Do not use INT data type to store true or false because SMALLINT uses 2 bytes while BOOLEAN uses 1 byte

### 2.17 Enums

- for human it seems a string but for postgres it is an integer
- Enums are a data type that allows you to create a set of predefined values that a column can take. It is a fixed set of values that a column can take
- Enums are useful when you have a fixed set of values that a column can take
- Recommended:
  - Use ENUM data type to store a fixed set of values
  - Do not use TEXT data type to store a fixed set of values
  - Do not use ENUM data type to store a dynamic set of values
- ORDER BY profile_status will order the column profile_status based on the order of the enum values and not based on the alphabetical order of the enum values
  - This can be useful when you want to order the column based on the order of the enum values
    - ex: grades: O, E, A, B, C, D, F
- ```sql
  DROP TYPE status;

  CREATE TYPE status AS ENUM('on vacation', 'focusing', 'out sick', 'working from home');

  ALTER TYPE status ADD VALUE 'working from office';

  ALTER TYPE status ADD VALUE 'live streaming' before 'focusing';

  ALTER TYPE status ADD VALUE 'hacking' after 'out sick';
  ```

- Deleting Enum can be tricky because if we remove one item from the enum we need to udpate the DB to remove the values from the column. See example file for more details

- Enum ordering behind the scenes:

  - `select * from pg_catalog.pg_enum;` to see the enums and you can see the `enumsortorder` column which shows the order of the enum values
  - `select \* from pg_catalog.pg_enum where enumtypid = 17311 order by enumsortorder;`

- enum_range function to get the range or the order of the enum values

  - `select enum_range(null::gh_status2);`

- Check Constraint vs Enum vs Integer:
  - Enum uses less storage than check constraint
  - Enum is more readable and concise than check constraint
  - Check constraint with TEXT is more flexible than enum so use check constraint when you need more flexibility ex: changing the values of the enum more frequently
  - You can also use an Integer for the enum values. It might not be readable but it is more compact than Enum

-- DAY 4 --

### 2.18 Timestamps

- https://www.postgresql.org/docs/current/datatype-datetime.html
- Postgres allows us to save date time in two ways
  - timestamp without timezone
    - in this postgres will totally ignore the tz info
    - `"timestamp" TIMESTAMP WITHOUT time zone` here WITHOUT time zone is by default
  - timestamp with timezone (Recommended)
    - In this postgres will convert it into utc and postgres will do the conversion when we pull the data
    - `"timestamp" TIMESTAMP WITH time zone`
    - `"timestamp2" timestamptz(6)` here the bound can be 0-6 which determines the fraction of seconds to be stored
      - if no bound mentioned it will take 6 as default
      - if bound is 0 it will round up the seconds
      - to round down use `date_trunc('second', now())`
- Inserting values in timestamp column?
  - four formats: ISO, SQL, German and Postgres
  - ISO 8601 (Recommended)
    - ex: 2025-03-11T14:15:30Z, 2025-03-11T14:15:30+00, 2025-03-11T14:15:30+05:30 (India tz), 2025-03-11T14:15:30+08:00 (SG tz), 2025-03-11T09:45:00-07:00 (Pacific Daylight Time during daylight savings)
    - Not ambiguous
  - Ambiguous data: Other formats ex: 2025-03-11 is ambiguous and does not have tz info. postgres will save it. But we should AVOID IT!
    - postgres will use the default ambiguity setting to define what is D M and Y. to see this setting use `show DATESTYLE;` which will show ex: `ISO, MDY`
      - use `set DATESTYLE = 'ISO, DMY';` to change DATESTYLE
  - Recommendation ✅:
    - Use ISO 8601
    - DMY or MDY is fine
  - There is another format called UNIX ex: 1741676088 which is 2025-03-11 14:54:48+08
    - to convert unix or epoch time into timestamp use: `to_timestamp` fn
  - Note: you can use UNIX or ISO 8601 both are good but I highly recommend ISO because it's widely accepted standard

### 2.19 Timezone

- it's tricky because we have political reasons along with geographical reasons
  - means we will have to take care of daylight saving time as well
- Recommendation ✅:
  - keep it in UTC in DB and only do the conversion when needed
    - postgres will handle the conversion for us when we use UTC format
  - use named timezone rather than using numbers for hours offset ex: +5:30
    - because hours offset might be wrong in some cases. but named timezones are more accurate
      - daylight saving
      - sign
        - `'2025-03-11 15:31:43'::timestamptz at time zone '-06:00'` is wrong for CST and '+06:00' is right and hence confusing. DON'T USE IT
        - https://www.postgresql.org/docs/current/datetime-posix-timezone-specs.html#:~:text=The%20offset%20fields,must%20have%20two.
        - It uses POSIX style which is the opposite of the ISO-8601 sign convention used elsewhere in PostgreSQL.
- Commands:
  - `show time zone;` to see time zone
  - you can change it using `SET time zone 'Europe/Rome';'. This is per session and will be lost when reconnected and will reset to db tz
  - `ALTER DATABASE master_postgres_demo SET TIME ZONE 'UTC'` will apply timezone at a global level irrespective of sessions
  - you can also set time zone in the postgres config file. you can find the location at `show config_file`
  - show tz names: `SELECT * FROM pg_timezone_names WHERE name like '%Singapore';`

### 2.20 Date and Time

- Ideally if we want to save date and time together we use timestamp but in some use cases we might want to save date and time separately rather than together ex: birthday where tz is not important. and date and time can be stored separately.
- Note: postgres has time and time_tz column
  - but time_tz is not recommended because it can be confusing sometimes without the date
  - if you need tz use timestamp instead and save date and time together
- magic strings: DON'T USE THIS! calculate yesterday tomorrow etc based on today instead. Best practice!!!
  - select 'yesterday'::TIMESTAMP;
  - select 'tomorrow'::TIMESTAMP;
  - select 'epoch'::TIMESTAMP;
  - select 'infinity'::TIMESTAMP;
  - select 'allballs'::time;
- to find current date and time etc, use the following constants:
  - `select CURRENT_DATE, CURRENT_TIMESTAMP, current_time;`
  - `select LOCALTIME, LOCALTIMESTAMP;`
  - AVOID `current_time` as it returns the tz info as well which is not useful without date. so use date or timestamp instead

## 3 Diving into Advanced Data Types

### 3.1 Arrays

- Note that JSON already has Arrays (we will see that in future) but we have a dedicated data type for arrays in postgress
- when to break data into separate columns or store them as array? My preference:
  - if you have a list of data that are related then save them as array ex: storing temperature list for today's date should be stored as array
  - if you have unrelated list of data then you can choose to save them separately in db columns.
- Syntax:
  - for create: `messagesReceived TEXT[], threadList TEXT[][],`
  - for insert: `ARRAY[...]` or `{...}`
  - `select temperatureForDate, temperatureForDate[0], temperatureForDate[1], temperatureForDate[2:3] , temperatureForDate[2:], temperatureForDate[1:] from arrays_demo;`
    - Note that array data type in postgres is not zero indexed. it's 1 indexed
    - you can use `[1:3]`, `[2:]` etc for slicing

### 3.2 Intervals

- it is used to store durations ex: to store duration of stay at a hotel. and it can be useful while finding if two stays by two guests overlap etc.
- command:
  - syntax: `select 'quantity unit'::interval` ex: `select '2 year 4 months 5 days 19 hours 34 seconds'::interval`
  - `show intervalstyle;` to check the current format: this is only for display
    - allowed values: postgres (default), iso_8601
      - No preference: both should be fine

### 3.3 Serial and BigSerial

- It is not a real data type
- It is an INTEGER data type under the hood (uses sequences) which is similar to INTEGER and with some additional features
- Traditionally used to create PRIMARY KEY but not recommended anymore as we have better way to create PRIMARY KEYs and we will see soon
- It is a good choice for PRIMARY KEY but not great
-

```
CREATE TABLE serial_demo (
	id SERIAL
);
```

is equivalent to

```
CREATE SEQUENCE serial_example_data_type AS INTEGER;
CREATE TABLE serial_demo (
	id integer NOT NULL DEFAULT nextval('serial_example_data_type')
);
ALTER SEQUENCE serial_example_data_type OWNED BY serial_demo.id;
```

- Note: Use BIGSERIAL instead of SERIAL because we should not think about saving space for primary keys. as it is very much possible that we might run out of that space if our product becomes viral.

- For sequence some times it might create a gap because it does nextval() update in a transaction which is good because it makes sure if we have two nextval() update request then only one is done in a transaction and the second one uses the next transaction and next id. so if current row id is at 10, if two users update at the same time. nextval() will not assign 11 for both but 11 for one and 12 for both. but for some reason if updating 11 fails and 12 is succesful then it will retry and the new id will be 13 creating a gap at 11.
  - this is done intentionally to avoid duplicates
- we can use SERIAL in other use cases where a sequence will be more useful
  - ex: bank tx ids.
  - sequences can start from any number and also allows us to insert any value at any point. which might be useful in bank txs to add custom prefix etc.
- Note: you can use `RETURNING` with `INSERT INTO` to return back the values

### 3.4 Sequence

- we can create custom Sequences to build our own sequence
- syntax:

```
CREATE SEQUENCE bank_tx_id
	AS BIGINT
	INCREMENT 1
	START 30000
	MINVALUE 1
	MAXVALUE 9223372036854775807
	-- how many values should be cached before it goes and checks for the next update. by default cache is 1. and it's ok to leave with the default
	CACHE 1;
```

- to increment use nextval fn: `SELECT nextval('bank_tx_id')`
- currVal fn: `SELECT currval('bank_tx_id')` to return currval only in the current session. it will not give you accurate id if the value was updated somewhere else
  - it only returns current value of the current transaction and not the global value
- `setval` fn: to set the sequence to a specific value. Be careful as it breaks the sequence and starts again with a new starting point
  - might be useful to set a higher value during migration etc

### 3.5 Identity

- Ideal for Primary key
- `id BIGINT GENERATED ALWAYS as IDENTITY`
  - why BIGINT instead of SERIAL or uuid we will discuss it during indexing
- To override the default primary key generation we can use `OVERRIDING SYSTEM VALUE` NOT RECOMMENDED ❌

  - This will only insert the value 9 but won't move the sequence to 9. hence we might end up with two rows with id 9
  - the solution to this will be to reset the sequence to 9 as well after using OVERRIDING SYSTEM VALUE
  - you can use `pg_get_serial_sequence` to get the sequence for `id` of a `table` and then you can use `setval('sequencename')` to reset the sequence

- GENERATED ALWAYS vs GENERATED BY DEFAULT
  - GENERATED ALWAYS will not allow us to set id explicitly unless we use OVERRIDING SYSTEM VALUE but GENERATED BY DEFAULT will allow us to set
  - both will not reset the sequence. we will have to do that manually with setval if we choose to override the identity
- Recommended:
  - Always use `GENERATED ALWAYS` since it's more strict and will avoid accidental id update
  - Avoid using OVERRIDE SYSTEM VALUE
  - use DEFAULT if you have to pass id

### 3.6 Composite types

- This is a type that is a composition of multiple types
- This is rarely used
- Most of the times we use JSON or discrete columns
- Ex:

```
CREATE TYPE blogpost as (
	title text,
	author text,
	category text[],
	tag text[],
	excerpt text
)
```

- It does not allow us to set constraints

### 3.7 NULL

- Null is an unknown value. It is not empty.
- Null is used to define constraint ex: `NOT NULL` which means not unknown
- Recommendation ✅:
  - use NOT NULL by default unless we explicitly want something to be NULLABLE
  - it will help in many operations such as grouping, querying, indexing, sorting etc
